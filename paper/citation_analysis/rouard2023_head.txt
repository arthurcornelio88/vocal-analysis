HYBRID TRANSFORMERS FOR MUSIC SOURCE SEPARATION
Simon Rouard, Francisco Massa, Alexandre Défossez

arXiv:2211.08553v1 [eess.AS] 15 Nov 2022

Meta AI
ABSTRACT
A natural question arising in Music Source Separation (MSS)
is whether long range contextual information is useful, or
whether local acoustic features are sufficient. In other fields,
attention based Transformers [1] have shown their ability to
integrate information over long sequences. In this work, we
introduce Hybrid Transformer Demucs (HT Demucs), an hybrid temporal/spectral bi-U-Net based on Hybrid Demucs [2],
where the innermost layers are replaced by a cross-domain
Transformer Encoder, using self-attention within one domain,
and cross-attention across domains. While it performs poorly
when trained only on MUSDB [3], we show that it outperforms Hybrid Demucs (trained on the same data) by 0.45 dB
of SDR when using 800 extra training songs. Using sparse attention kernels to extend its receptive field, and per source
fine-tuning, we achieve state-of-the-art results on MUSDB
with extra training data, with 9.20 dB of SDR.
Index Terms— Music Source Separation, Transformers
1. INTRODUCTION
Since the 2015 Signal Separation Evaluation Campaign
(SiSEC) [4], the community of MSS has mostly focused
on the task of training supervised models to separate songs
into 4 stems: drums, bass, vocals and other (all the other
instruments). The reference dataset that is used to benchmark
MSS is MUSDB18 [3, 5] which is made of 150 songs in two
versions (HQ and non-HQ). Its training set is composed of
87 songs, a relatively small corpus compared with other deep
learning based tasks, where Transformer [1] based architectures have seen widespread success and adoption, such as
vision [6, 7] or natural language tasks [8]. Source separation
is a task where having a short context or a long context as input both make sense. Conv-Tasnet [9] uses about one second
of context to perform the separation, using only local acoustic
features. On the other hand, Demucs [10] can use up to 10
seconds of context, which can help to resolve ambiguities
in the input. In the present work, we aim at studying how
Transformer architectures can help leverage this context, and
what amount of data is required to train them.
We first present in Section 3 a novel architecture, Hybrid
Transformer Demucs (HT Demucs), which replaces the innermost layers of the original Hybrid Demucs architecture [2]

with Transformer layers, applied both in the time and spectral
representation, using self-attention within one domain, and
cross-attention across domains. As Transformers are usually
data hungry, we leverage an internal dataset composed of 800
songs on top of the MUSDB dataset, described in Section 4.
Our second contribution is to evaluate extensively this
new architecture in Section 5, with various settings (depth,
number of channels, context length, augmentations etc.). We
show in particular that it improves over the baseline Hybrid
Demucs architecture (retrained on the same data) by 0.35 dB.
Finally, we experiment with increasing the context duration using sparse kernels based with Locally Sensitive Hashing to overcome memory issues during training, and finetuning procedure, thus achieving a final SDR of 9.20 dB on
the test set of MUSDB.
We release the training code, pre-trained models, and
samples on our github facebookresearch/demucs.
2. RELATED WORK
A traditional split for MSS methods is between spectrogram based and waveform based models. The former includes models like Open-Unmix [11], a biLSTM with fully
connected that predicts a mask on the input spectrogram
or D3Net [12] which uses dilated convolutional blocks
with dense connections. More recently, using complexspectrogram as input and output was favored [13] as it provides a richer representation and removes the topline given
by the Ideal-Ratio-Mask. The latest spectrogram model,
Band-Split RNN [14], combines this idea, along with multiple dual-path RNNs [15], each acting in carefully crafted
frequency band. It currently achieves the state-of-the-art on
MUSDB with 8.9 dB. Waveform based models started with
Wave-U-Net [16], which served as the basis for Demucs [10],
a time domain U-Net with a bi-LSTM between the encoder
and decoder. Around the same time, Conv-TasNet showed
competitive results [9, 10] using residual dilated convolution
blocks to predict a mask over a learnt representation. Finally,
a recent trend has been to use both temporal and spectral
domains, either through model blending, like KUIELABMDX-Net [17], or using a bi-U-Net structure with a shared
backbone as Hybrid Demucs [2]. Hybrid Demucs was the first
ranked architecture at the latest MDX MSS Competition [18],
although it is now surpassed by Band-Split RNN.

Table 1: Comparison with baselines on the test set of
MUSDB HQ (methods with a ∗ are reported on the non HQ
version). “Extra?” indicates the number of extra songs used
at train time, † indicates that only mixes are used. “fine tuned”
indices per source fine-tuning.
Test SDR in dB
Architecture

Extra?

All

Drums

Bass

Other

IRM oracle

N/A

8.22
