# Vocal Analysis - AnÃ¡lise BioacÃºstica M1/M2

AnÃ¡lise computacional de mecanismos larÃ­ngeos (M1/M2) em gravaÃ§Ãµes de Choro brasileiro, com foco na voz de Ademilde Fonseca.

## Objetivo

Criticar o sistema de classificaÃ§Ã£o vocal "Fach" atravÃ©s de uma anÃ¡lise fisiolÃ³gica dos mecanismos larÃ­ngeos, extraindo features explicÃ¡veis (f0, HNR, CPPS) de Ã¡udios de canto.

## Stack

- **torchcrepe**: ExtraÃ§Ã£o SOTA de f0 (pitch)
- **parselmouth** (Praat): HNR, CPPS, Jitter, Shimmer
- **xgboost**: ClassificaÃ§Ã£o tabular M1/M2
- **seaborn/matplotlib**: VisualizaÃ§Ãµes acadÃªmicas
- **google-generativeai**: GeraÃ§Ã£o de relatÃ³rios narrativos multimodais com Gemini 2.0 Flash

## Setup

### Requisitos

- Python 3.10+
- [UV](https://github.com/astral-sh/uv) (gerenciador de pacotes)
- (Opcional) API Key do Google Gemini para relatÃ³rios com IA

### InstalaÃ§Ã£o

```bash
# Clonar o repositÃ³rio
git clone <repo-url>
cd vocal-analysis

# Instalar dependÃªncias
uv sync

# Instalar dependÃªncias de desenvolvimento (ruff, pytest, jupyter)
uv sync --extra dev
```

### Configurar Gemini (opcional)

Para gerar relatÃ³rios narrativos com IA:

1. Acesse [Google AI Studio](https://aistudio.google.com/apikey)
2. Clique em "Create API Key"
3. Configure a variÃ¡vel de ambiente:

```bash
export GEMINI_API_KEY=sua_chave_aqui
```

Ou adicione ao seu `.bashrc`/`.zshrc` para persistir.

## Estrutura do Projeto

```
vocal-analysis/
â”œâ”€â”€ src/vocal_analysis/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ audio.py              # load_audio(), normalize_audio()
â”‚   â”‚   â””â”€â”€ process_ademilde.py   # Script de extraÃ§Ã£o de features
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ extraction.py         # Pipeline hÃ­brido Crepe + Praat
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ exploratory.py        # AnÃ¡lise M1/M2, clustering
â”‚   â”‚   â”œâ”€â”€ run_analysis.py       # Script de anÃ¡lise completa
â”‚   â”‚   â””â”€â”€ llm_report.py         # GeraÃ§Ã£o de relatÃ³rio com Gemini
â”‚   â”œâ”€â”€ modeling/
â”‚   â”‚   â””â”€â”€ classifier.py         # XGBoost para classificaÃ§Ã£o M1/M2
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â””â”€â”€ plots.py              # Plots acadÃªmicos
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ pitch.py              # ConversÃ£o Hz â†” Notas (A4, C5, etc)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Ãudios originais (.mp3)
â”‚   â””â”€â”€ processed/                # CSVs, JSONs, logs
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ plots/                    # GrÃ¡ficos gerados
â”‚   â””â”€â”€ models/                   # Modelos treinados
â””â”€â”€ tests/
```

## Uso

### 1. Adicionar Ã¡udios

Coloque os arquivos MP3 em `data/raw/`:

```
data/raw/
â”œâ”€â”€ Apanhei-te Cavaquinho.mp3
â”œâ”€â”€ brasileirinho.mp3
â””â”€â”€ delicado.mp3
```

### 2. Processar Ã¡udios (extrair features)

```bash
uv run python -m vocal_analysis.preprocessing.process_ademilde
```

**Outputs gerados:**
- `data/processed/ademilde_features.csv` - Features por frame
- `data/processed/ademilde_metadata.json` - Metadados estruturados
- `data/processed/processing_log.md` - Log legÃ­vel
- `outputs/plots/*_f0.png` - Contornos de pitch

### 3. Rodar anÃ¡lise exploratÃ³ria

```bash
uv run python -m vocal_analysis.analysis.run_analysis
```

**Outputs gerados:**
- `outputs/plots/mechanism_analysis.png` - 4 plots de anÃ¡lise M1/M2
- `outputs/plots/mechanism_clusters.png` - Clustering GMM
- `outputs/analise_ademilde.md` - RelatÃ³rio estruturado
- `outputs/relatorio_llm.md` - RelatÃ³rio narrativo com Gemini (se API configurada)

#### RelatÃ³rio LLM Multimodal

Se `GEMINI_API_KEY` estiver configurada, o script gera um relatÃ³rio narrativo usando Gemini 2.0 Flash com:

- **AnÃ¡lise multimodal**: O LLM recebe os plots junto com os dados numÃ©ricos
- **Links clicÃ¡veis**: ReferÃªncias a grÃ¡ficos incluem links markdown (ex: `[brasileirinho_f0](plots/brasileirinho_f0.png)`)
- **Ãndice de figuras**: Lista completa de visualizaÃ§Ãµes no final do relatÃ³rio

### 4. Features extraÃ­das

| Coluna | DescriÃ§Ã£o |
|--------|-----------|
| `time` | Timestamp em segundos |
| `f0` | FrequÃªncia fundamental (Hz) |
| `confidence` | ConfianÃ§a da estimativa de pitch (0-1) |
| `hnr` | Harmonic-to-Noise Ratio (dB) |
| `song` | Nome da mÃºsica |
| `cpps_global` | Cepstral Peak Prominence |

### 5. ClassificaÃ§Ã£o M1/M2

Com dados rotulados:

```python
from vocal_analysis.modeling import train_mechanism_classifier
import pandas as pd

df = pd.read_csv("data/processed/ademilde_features.csv")
df["mechanism_label"] = ...  # 0=M1 (peito), 1=M2 (cabeÃ§a)

model = train_mechanism_classifier(df)
```

## UtilitÃ¡rios

### ConversÃ£o Hz â†” Notas

```python
from vocal_analysis.utils.pitch import hz_to_note, note_to_hz

hz_to_note(440.0)        # "A4"
hz_to_note(261.63)       # "C4"
note_to_hz("G5")         # 783.99
```

## Desenvolvimento

### Linting

```bash
uv run ruff check src/
uv run ruff format src/
```

### Testes

```bash
uv run pytest -v
```

## Metodologia Detalhada

Para entender em profundidade as escolhas metodolÃ³gicas, parÃ¢metros tÃ©cnicos e justificativas acadÃªmicas de cada componente do pipeline, consulte:

**ğŸ“– [METODOLOGIA.md](METODOLOGIA.md)**

Este documento descreve:
- Escolha do CREPE vs mÃ©todos tradicionais de autocorrelaÃ§Ã£o
- ParÃ¢metros de prÃ©-processamento (normalizaÃ§Ã£o, hop length, thresholds)
- Detalhamento de cada feature bioacÃºstica (f0, HNR, CPPS, Jitter, Shimmer, Formantes)
- Features de agilidade articulatÃ³ria (f0 velocity, taxa silÃ¡bica)
- MÃ©todos de classificaÃ§Ã£o M1/M2 (Threshold, GMM, XGBoost)
- Estrutura de dados e workflow de execuÃ§Ã£o
- LimitaÃ§Ãµes reconhecidas e conformidade acadÃªmica

## ReferÃªncias

- **CREPE**: [Kim et al., 2018 - CREPE: A Convolutional Representation for Pitch Estimation](https://arxiv.org/abs/1802.06182)
- **Praat**: [Boersma & Weenink - Praat: doing phonetics by computer](https://www.praat.org)
- **Mecanismos LarÃ­ngeos**: Roubeau, B., Henrich, N., & Castellengo, M. (2009). Laryngeal vibratory mechanisms
